{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import scipy.stats as stats\n",
      "import astropy.stats as astats\n",
      "from astropy.table import Table\n",
      "import numpy.random as random\n",
      "from hlmean import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mode2(data,**kwargs):\n",
      "# note: provide bins and (optionally) range keywords to not use\n",
      "# defaults of np.histogram (10 bins, full range)\n",
      "    counts,edges=np.histogram(data,**kwargs)\n",
      "    whmax=np.argmax(counts)\n",
      "    mode=(edges[whmax]+edges[whmax+1])/2\n",
      "    return(mode)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1A) Efficiency of each data with ndata=100, foutlier=0"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Calculating (nsims,ndata) dataset of velocity dispersions, from outlier and normal clusters.\n",
      "nsims = 1.0e4\n",
      "ndata = 1.0e2\n",
      "foutlier = 0.0\n",
      "isoutlier = random.rand(nsims,ndata) < foutlier #NOTE: rand() generates [0,1], randn() generates N(0,1)\n",
      "data = (1-isoutlier)*(random.randn(nsims,ndata)*930.0+3150.0) + isoutlier*(random.randn(nsims,ndata)*200.0+4750.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Locations of data for each simulation\n",
      "\n",
      "means = np.mean(data,axis=1)\n",
      "medians = np.median(data,axis=1)\n",
      "modes = np.array([mode2(data_i,bins=np.arange(data_i.min(),data_i.max(),50)) for data_i in data])\n",
      "hlmeans = np.array([hlmean(data_i) for data_i in data])\n",
      "trimmeans = np.array([stats.tmean(data_i,limits=np.percentile(data_i,(10,90))) for data_i in data])\n",
      "biweights = np.array([astats.biweight_location(data_i) for data_i in data])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '\\n\\nBIASES OF ESTIMATORS\\n'\n",
      "print 'Estimated Mean : 3150 km/s\\n'\n",
      "unit = 'km/s'\n",
      "error = lambda x: 100.0*(1.0-(np.abs(x-3150.0)/3150.0))\n",
      "print 'Mean: ',np.mean(means),unit,'\\t', '(Accuracy: ',error(np.mean(means)),'%)'\n",
      "print 'Median: ',np.mean(medians),unit,'\\t', '(Accuracy: ',error(np.mean(medians)),'%)'\n",
      "print 'Mode: ',np.mean(modes),unit,'\\t', '(Accuracy: ',error(np.mean(modes)),'%)'\n",
      "print 'HL Mean: ',np.mean(hlmeans),unit, '\\t','(Accuracy: ',error(np.mean(hlmeans)),'%)'\n",
      "print 'Trimmed Mean: ',np.mean(trimmeans),unit, '(Accuracy: ',error(np.mean(trimmeans)),'%)'\n",
      "print 'Biweight: ',np.mean(biweights),unit, '\\t','(Accuracy: ',error(np.mean(biweights)),'%)'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "BIASES OF ESTIMATORS\n",
        "\n",
        "Estimated Mean : 3150 km/s\n",
        "\n",
        "Mean:  3150.51243718 km/s \t(Accuracy:  99.9837321532 %)\n",
        "Median:  3150.90483887 km/s \t(Accuracy:  99.9712749566 %)\n",
        "Mode:  2974.34608207 km/s \t(Accuracy:  94.4236851449 %)\n",
        "HL Mean:  3150.49670535 km/s \t(Accuracy:  99.9842315761 %)\n",
        "Trimmed Mean:  3150.50272476 km/s (Accuracy:  99.9840404837 %)\n",
        "Biweight:  3150.60237338 km/s \t(Accuracy:  99.9808770355 %)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All Accuracies shown are the accuracies in Means (or bias) which are calculated as follows :-\n",
      "\n",
      "Accuracy = $\\dfrac{|\\bar{v} - \\bar{v}_{true}|}{\\bar{v}_{true}} \\times 100 \\%$\n",
      "\n",
      "where $\\bar{v}$ is the mean velocity per simulation, and $\\bar{v}_{true}$ is the true velocity = 3150 km/s"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '\\n\\nSPREADS OF ESTIMATORS\\n'\n",
      "serr = 930.0/np.sqrt(ndata)\n",
      "error = lambda x: 100.0*(1.0-(np.abs(x-serr)/serr))\n",
      "print 'Mean: ',np.std(means,ddof=1),unit\n",
      "print 'Median: ',np.std(medians,ddof=1),unit\n",
      "print 'Mode: ',np.std(modes,ddof=1),unit\n",
      "print 'HL Mean: ',np.std(hlmeans,ddof=1),unit\n",
      "print 'Trimmed Mean: ',np.std(trimmeans,ddof=1),unit\n",
      "print 'Biweight: ',np.std(biweights,ddof=1),unit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "SPREADS OF ESTIMATORS\n",
        "\n",
        "Mean:  92.4245759646 km/s\n",
        "Median:  115.007075972 km/s\n",
        "Mode:  483.259399153 km/s\n",
        "HL Mean:  94.8474169701 km/s\n",
        "Trimmed Mean:  94.8930635455 km/s\n",
        "Biweight:  98.4978390292 km/s\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Except for the Mode, all the statistics have very little bias over a 100 runs. However the mean has the least spread of all.\n",
      "\n",
      "So for a Gaussian Distribution with no outliers, the best choice of statistic is the __Mean__."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1B) Efficiency of ndata = 5,25,100 for foutlier = 0.1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nsims = 1.0e4\n",
      "ndata_array = np.array([5,25,100])*1.0\n",
      "mean_vals = np.zeros((6,3))\n",
      "std_vals = np.zeros((6,3))\n",
      "foutlier = 0.1\n",
      "est_mean = 3150.0\n",
      "accuracy = lambda x: 100.0*(1.0-(np.abs(x-est_mean)/est_mean))\n",
      "accuracy_array = np.zeros((6,3))\n",
      "for ind,ndata in enumerate(ndata_array):\n",
      "    isoutlier = random.rand(nsims,ndata) < foutlier #NOTE: rand() generates [0,1], randn() generates N(0,1)\n",
      "    data = (1-isoutlier)*(random.randn(nsims,ndata)*930.0+3150.0) + isoutlier*(random.randn(nsims,ndata)*200.0+4750.0)\n",
      "    #Locations of data for each simulation\n",
      "\n",
      "    means = np.mean(data,axis=1)\n",
      "    medians = np.median(data,axis=1)\n",
      "    modes = np.array([mode2(data_i,bins=np.arange(data_i.min(),data_i.max(),50)) for data_i in data])\n",
      "    hlmeans = np.array([hlmean(data_i) for data_i in data])\n",
      "    trimmeans = np.array([stats.tmean(data_i,limits=np.percentile(data_i,(10,90))) for data_i in data])\n",
      "    biweights = np.array([astats.biweight_location(data_i) for data_i in data])\n",
      "    mean_vals[0,ind],std_vals[0,ind],accuracy_array[0,ind] = np.mean(means),np.std(means),accuracy(np.mean(means))\n",
      "    mean_vals[1,ind],std_vals[1,ind],accuracy_array[1,ind] = np.mean(medians),np.std(medians),accuracy(np.mean(medians))\n",
      "    mean_vals[2,ind],std_vals[2,ind],accuracy_array[2,ind] = np.mean(modes),np.std(modes),accuracy(np.mean(modes))\n",
      "    mean_vals[3,ind],std_vals[3,ind],accuracy_array[3,ind] = np.mean(hlmeans),np.std(hlmeans),accuracy(np.mean(hlmeans))\n",
      "    mean_vals[4,ind],std_vals[4,ind],accuracy_array[4,ind] = np.mean(trimmeans),np.std(trimmeans),accuracy(np.mean(trimmeans))\n",
      "    mean_vals[5,ind],std_vals[5,ind],accuracy_array[5,ind] = np.mean(biweights),np.std(biweights),accuracy(np.mean(biweights))\n",
      "\n",
      "rows = ['Mean','Median','Mode','HLMean','Trimmed Mean','Biweight']\n",
      "tablearray = [rows,mean_vals[:,0],accuracy_array[:,0],mean_vals[:,1],accuracy_array[:,1],mean_vals[:,2],accuracy_array[:,2]]\n",
      "headings = ('Statistic','ndata=5','accuracy1','ndata=25','accuracy2','ndata=100','accuracy3')\n",
      "t_means = Table(tablearray,names=headings)\n",
      "t_vars = Table([rows,std_vals[:,0],std_vals[:,1],std_vals[:,2]],names=('Statistic','ndata=5','ndata=25','ndata=100'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 253
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'BIAS COMPARISON\\n'\n",
      "print 'Estimated Mean: ',est_mean,'km/s \\n'\n",
      "t_means.pprint(max_width=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BIAS COMPARISON\n",
        "\n",
        "Estimated Mean:  3150.0 km/s \n",
        "\n",
        " Statistic      ndata=5      accuracy1      ndata=25     accuracy2     ndata=100     accuracy3  \n",
        "------------ ------------- ------------- ------------- ------------- ------------- -------------\n",
        "        Mean 3310.20727375 94.9140548017 3309.86639561 94.9248763297 3309.70038714 94.9301464399\n",
        "      Median 3303.68392649 95.1211451908 3285.42894219  95.700668502 3282.21945456  95.802556998\n",
        "        Mode 2240.91820512   71.14026048 2798.80080746 88.8508192845 3070.98635353 97.4916302708\n",
        "      HLMean 3313.10192069  94.822161248 3310.75690211 94.8966062822 3311.65002358 94.8682532196\n",
        "Trimmed Mean  3313.2058895 94.8188606507 3315.80819337 94.7362478295 3319.01252813 94.6345229164\n",
        "    Biweight 3308.88106085 94.9561567984 3304.33922436 95.1003420838 3307.03561627 95.0147423408\n"
       ]
      }
     ],
     "prompt_number": 254
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'SPREAD COMPARISON\\n'\n",
      "#print 'Standard Deviation of the sample: ',(foutlier*200.0 + (1.0-foutlier)*930.0)/np.sqrt(ndata_array)\n",
      "t_vars"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "SPREAD COMPARISON\n",
        "\n"
       ]
      },
      {
       "html": [
        "<table id=\"table4585589456\"><thead><tr><th>Statistic</th><th>ndata=5</th><th>ndata=25</th><th>ndata=100</th></tr></thead><tr><td>Mean</td><td>449.907916783</td><td>198.206754343</td><td>100.621968178</td></tr><tr><td>Median</td><td>567.874748212</td><td>259.760237353</td><td>131.008496479</td></tr><tr><td>Mode</td><td>708.75944504</td><td>739.177202487</td><td>609.490039326</td></tr><tr><td>HLMean</td><td>479.647514068</td><td>212.671058222</td><td>108.425265071</td></tr><tr><td>Trimmed Mean</td><td>499.893412045</td><td>217.543713498</td><td>109.749443084</td></tr><tr><td>Biweight</td><td>540.83063425</td><td>223.432535934</td><td>111.843456001</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 255,
       "text": [
        "<Table rows=6 names=('Statistic','ndata=5','ndata=25','ndata=100')>\n",
        "array([('Mean', 449.90791678314497, 198.20675434347527, 100.62196817833451),\n",
        "       ('Median', 567.8747482116535, 259.7602373532516, 131.0084964791102),\n",
        "       ('Mode', 708.7594450397381, 739.1772024873629, 609.4900393259484),\n",
        "       ('HLMean', 479.6475140679535, 212.6710582223871, 108.42526507054993),\n",
        "       ('Trimmed Mean', 499.89341204474334, 217.54371349800942, 109.74944308383171),\n",
        "       ('Biweight', 540.8306342495292, 223.43253593375374, 111.84345600060722)], \n",
        "      dtype=[('Statistic', 'S12'), ('ndata=5', '<f8'), ('ndata=25', '<f8'), ('ndata=100', '<f8')])"
       ]
      }
     ],
     "prompt_number": 255
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With outliers, the choice of statistic is tricky. \n",
      "\n",
      "__High-z Studies__\n",
      "\n",
      "Median appears to have the least bias while Mode has the most. However, they both have very high spreads, which means they are not as efficient. The same goes for the Biweight Statistic. Based off the spreads, I would go with either __HL-Mean__ or __Mean__ as my statistic, since they are fairly accurate (least spreads) and relatively unbiased.\n",
      "\n",
      "__SDSS Case__\n",
      "\n",
      "Median has the least bias (1% more than the mean or median); however its spread is higher.  Based on the numbers given, I would go with either __Mean__ (which is the most efficient, given the least spread) or __Biweight__ (smaller spread, less bias than mean). \n",
      "\n",
      "__Ideal Intensive Study Case__\n",
      "\n",
      "Here the Mode clearly stands out as the most unbiased estimator of location, however it is still plagued by a wide spread. Trading off between bias and spread, I would choose the __Median__ in this case. The others have more bias than the Mode or Median, but have less spread.\n",
      "\n",
      "\n",
      "It is worth noting that small (~1%) differences in accuracy can be ignored since they are calculated from a Monte Carlo Code. The Mode is also dependent on binning."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2A) Velocity Dispersions for ndata = 100, foutlier = 0"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$Data = (1-f) N(\\mu,\\sigma) + f [0,6500)$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Generating data\n",
      "nsims = 1.0e4\n",
      "ndata = 100.0\n",
      "foutlier = 0.0\n",
      "isoutlier = np.random.rand(nsims,ndata) < foutlier\n",
      "#Outliers will be drawn from a uniform distribution - [0,6500] km/s\n",
      "data = (1.0 - isoutlier)*(np.random.randn(nsims,ndata)*930.0 + 3150) + isoutlier*np.random.rand(nsims,ndata)*6500.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 258
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Sample Standard Deviation\n",
      "st_devs = np.std(data,axis=1,ddof=1)\n",
      "\n",
      "#Mean Absolute Deviation\n",
      "absvals_mean = np.array([np.absolute(data_i - data_i.mean()) for data_i in data])\n",
      "mean_devs = np.mean(absvals_mean,axis=1)/0.7979    #Applying the Gaussian Corrections\n",
      "\n",
      "#Median Absolute Deviation\n",
      "absvals_med = np.array([np.absolute(data_i - data_i.mean()) for data_i in data])\n",
      "med_devs = np.median(absvals_med,axis=1)/0.6745\n",
      "\n",
      "#Biweight Standard Deviation\n",
      "biw_devs = np.array([astats.biweight_midvariance(data_i) for data_i in data])\n",
      "\n",
      "#IQR\n",
      "d25 = np.array([np.percentile(data_i,[25,75])[0] for data_i in data])\n",
      "d75 = np.array([np.percentile(data_i,[25,75])[1] for data_i in data])\n",
      "iqr_devs = (d75-d25)/1.349\n",
      "#Trimmed Std\n",
      "trim_devs = np.array([stats.tstd(data_i, limits = np.percentile(data_i,[10,90])) for data_i in data])*1.49"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 259
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '\\n\\nBIASES AND SPREADS OF ESTIMATORS\\n'\n",
      "print '\\nTrue Velocity Dispersion = 930 km/s\\n'\n",
      "unit = 'km/s'\n",
      "error = lambda x: 100.0*(1.0-(np.absolute(x-930.0)/930.0))\n",
      "print 'STATISTIC\\t','\\t   MEAN\\t','\\t\\tSTD\\t\\n'\n",
      "print 'Standard Deviation:\\t\\t  ',np.mean(st_devs),unit,'\\t',np.std(st_devs,ddof=1),unit,'\\t\\t', '(Accuracy: ',error(np.mean(st_devs)),'%)'\n",
      "print 'Mean Absolute Deviation:\\t\\t  ',np.mean(mean_devs),unit,'\\t',np.std(mean_devs,ddof=1),unit,'\\t\\t', '(Accuracy: ',error(np.mean(mean_devs)),'%)'\n",
      "print 'Median Absolute Deviation:',np.mean(med_devs),unit,'\\t',np.std(med_devs,ddof=1),unit,'\\t\\t', '(Accuracy: ',error(np.mean(med_devs)),'%)'\n",
      "print 'Biweight STD:\\t\\t  ',np.mean(biw_devs),unit,'\\t',np.std(biw_devs,ddof=1),unit, '\\t\\t','(Accuracy: ',error(np.mean(biw_devs)),'%)'\n",
      "print 'IQR:\\t\\t\\t  ',np.mean(iqr_devs),unit,'\\t',np.std(iqr_devs,ddof=1),unit,'\\t', '\\t(Accuracy: ',error(np.mean(iqr_devs)),'%)'\n",
      "print '10% Trimmed STD:\\t  ',np.mean(trim_devs),unit,'\\t',np.std(trim_devs,ddof=1),unit, '\\t\\t','(Accuracy: ',error(np.mean(trim_devs)),'%)'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "BIASES AND SPREADS OF ESTIMATORS\n",
        "\n",
        "\n",
        "True Velocity Dispersion = 930 km/s\n",
        "\n",
        "STATISTIC\t\t   MEAN\t\t\tSTD\t\n",
        "\n",
        "Standard Deviation:\t\t   927.99546461 km/s \t66.6265004132 km/s \t\t(Accuracy:  99.7844585602 %)\n",
        "Mean Absolute Deviation:\t\t   925.723352178 km/s \t70.8039938465 km/s \t\t(Accuracy:  99.5401453955 %)\n",
        "Median Absolute Deviation: 928.396305373 km/s \t108.168507363 km/s \t\t(Accuracy:  99.8275597175 %)\n",
        "Biweight STD:\t\t   933.355467944 km/s \t69.642499594 km/s \t\t(Accuracy:  99.6391969952 %)\n",
        "IQR:\t\t\t   917.220901251 km/s \t107.639482474 km/s \t\t(Accuracy:  98.6259033603 %)\n",
        "10% Trimmed STD:\t   925.313417119 km/s \t82.8244802558 km/s \t\t(Accuracy:  99.4960663569 %)\n"
       ]
      }
     ],
     "prompt_number": 262
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All Accuracies shown are the accuracies in Means (or bias) which are calculated as follows :-\n",
      "\n",
      "Accuracy = $\\dfrac{|\\sigma - \\sigma_{true}|}{\\sigma_{true}} \\times 100 \\%$\n",
      "\n",
      "where $\\sigma$ is the velocity dispersion per simulation, and $\\sigma_{true}$ is the true velocity dispersion = 930 km/s\n",
      "\n",
      "For this run, it seems the best estimate of the standard deviation of the distribution for the case of a perfect Gaussian ($f_{outliers} = 0$), it seems the __Gaussian Standard Deviation__ gives the most unbiased result with the least spread. The Median Absolute Deviation comes a close second!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2B) Velocity Dispersions for ndata = 5,25,100 and foutlier = 0.1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Generating data\n",
      "nsims = 1.0e4\n",
      "ndata_array = np.array([5,25,100])*1.0\n",
      "foutlier = 0.1\n",
      "mean_vals = np.zeros((6,3))\n",
      "std_vals = np.zeros((6,3))\n",
      "est_mean = 930.0\n",
      "accuracy = lambda x: 100.0*(1.0-(np.abs(x-est_mean)/est_mean))\n",
      "accuracy_array = np.zeros((6,3))\n",
      "for ind,ndata in enumerate(ndata_array):\n",
      "    isoutlier = np.random.rand(nsims,ndata) < foutlier\n",
      "    #Normals from Normal D, Outliers from uniform D - [0,6500] km/s\n",
      "    data = (1.0 - isoutlier)*(np.random.randn(nsims,ndata)*930.0 + 3150.0) + isoutlier*np.random.rand(nsims,ndata)*6500.0\n",
      "    #Sample Standard Deviation\n",
      "    st_devs = np.std(data,axis=1,ddof=1)\n",
      "\n",
      "    #Mean Absolute Deviation\n",
      "    absvals_mean = np.array([np.absolute(data_i - data_i.mean()) for data_i in data])\n",
      "    mean_devs = np.mean(absvals_mean,axis=1)/0.7979    #Applying the Gaussian Corrections\n",
      "\n",
      "    #Median Absolute Deviation\n",
      "    absvals_med = np.array([np.absolute(data_i - data_i.mean()) for data_i in data])\n",
      "    med_devs = np.median(absvals_med,axis=1)/0.6745\n",
      "\n",
      "    #Biweight Standard Deviation\n",
      "    biw_devs = np.array([astats.biweight_midvariance(data_i) for data_i in data])\n",
      "\n",
      "    #IQR\n",
      "    d25 = np.array([np.percentile(data_i,[25,75])[0] for data_i in data])\n",
      "    d75 = np.array([np.percentile(data_i,[25,75])[1] for data_i in data])\n",
      "    iqr_devs = (d75-d25)/1.349\n",
      "\n",
      "    #Trimmed Std\n",
      "    trim_devs = np.array([stats.tstd(data_i, limits = np.percentile(data_i,[10,90])) for data_i in data])*1.49\n",
      "    \n",
      "    mean_vals[0,ind],std_vals[0,ind],accuracy_array[0,ind] = np.mean(st_devs),np.std(st_devs,ddof=1),accuracy(np.mean(st_devs))\n",
      "    mean_vals[1,ind],std_vals[1,ind],accuracy_array[1,ind] = np.mean(mean_devs),np.std(mean_devs,ddof=1),accuracy(np.mean(mean_devs))\n",
      "    mean_vals[2,ind],std_vals[2,ind],accuracy_array[2,ind] = np.mean(med_devs),np.std(med_devs,ddof=1),accuracy(np.mean(med_devs))\n",
      "    mean_vals[3,ind],std_vals[3,ind],accuracy_array[3,ind] = np.mean(biw_devs),np.std(biw_devs,ddof=1),accuracy(np.mean(biw_devs))\n",
      "    mean_vals[4,ind],std_vals[4,ind],accuracy_array[4,ind] = np.mean(iqr_devs),np.std(iqr_devs,ddof=1),accuracy(np.mean(iqr_devs))\n",
      "    mean_vals[5,ind],std_vals[5,ind],accuracy_array[5,ind] = np.mean(trim_devs),np.std(trim_devs,ddof=1),accuracy(np.mean(trim_devs))\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 263
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = ['St Dev','Mean Dev','Median Dev','Biweight','IQR','Trimmed STD']\n",
      "tablearray = [rows,mean_vals[:,0],accuracy_array[:,0],mean_vals[:,1],accuracy_array[:,1],mean_vals[:,2],accuracy_array[:,2]]\n",
      "headings = ('Statistic','ndata=5','accuracy5','ndata=25','accuracy25','ndata=100','accuracy100')\n",
      "t_means = Table(tablearray,names=headings)\n",
      "t_vars = Table([rows,std_vals[:,0],std_vals[:,1],std_vals[:,2]],names=('Statistic','ndata=5','ndata=25','ndata=100'))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 264
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'BIAS COMPARISON\\n'\n",
      "print 'Estimated Mean: ',est_mean,'\\n'\n",
      "t_means.pprint(max_width=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BIAS COMPARISON\n",
        "\n",
        "Estimated Mean:  930.0 \n",
        "\n",
        " Statistic     ndata=5      accuracy5      ndata=25     accuracy25    ndata=100    accuracy100 \n",
        "----------- ------------- ------------- ------------- ------------- ------------- -------------\n",
        "     St Dev 989.434135307 93.6092327627 1052.21450229 86.8586556672 1060.10301265 86.0104287472\n",
        "   Mean Dev 935.329917216  99.426890622  1022.9589612 90.0044127743 1036.10706861 88.5906377838\n",
        " Median Dev 961.554381575 96.6070557446 1002.31318311 92.2243889129 1002.89056513 92.1623048243\n",
        "   Biweight 847.472619156 91.1260880812 1026.33424923 89.6414785778 1046.64182357 87.4578684329\n",
        "        IQR 746.207881349 80.2374065967 951.609591991 97.6763879579 990.532548442 93.4911238234\n",
        "Trimmed STD 786.991642958 84.6227573073 966.386542116 96.0874685896 1008.25534338 91.5854469486\n"
       ]
      }
     ],
     "prompt_number": 265
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'SPREAD COMPARISON\\n'\n",
      "t_vars"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "SPREAD COMPARISON\n",
        "\n"
       ]
      },
      {
       "html": [
        "<table id=\"table4929339728\"><thead><tr><th>Statistic</th><th>ndata=5</th><th>ndata=25</th><th>ndata=100</th></tr></thead><tr><td>St Dev</td><td>381.845200304</td><td>165.950632556</td><td>79.7898201374</td></tr><tr><td>Mean Dev</td><td>366.706558779</td><td>167.356907378</td><td>82.1866791269</td></tr><tr><td>Median Dev</td><td>476.749803571</td><td>234.089235589</td><td>118.269567247</td></tr><tr><td>Biweight</td><td>410.73149671</td><td>175.376223168</td><td>84.9417024593</td></tr><tr><td>IQR</td><td>441.427624451</td><td>227.807690432</td><td>117.153540416</td></tr><tr><td>Trimmed STD</td><td>465.44974584</td><td>187.515077993</td><td>92.8625738981</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 266,
       "text": [
        "<Table rows=6 names=('Statistic','ndata=5','ndata=25','ndata=100')>\n",
        "array([('St Dev', 381.84520030361597, 165.95063255620775, 79.78982013738847),\n",
        "       ('Mean Dev', 366.70655877924804, 167.3569073780675, 82.1866791268502),\n",
        "       ('Median Dev', 476.74980357058223, 234.08923558949934, 118.26956724721389),\n",
        "       ('Biweight', 410.7314967100714, 175.37622316816473, 84.94170245926922),\n",
        "       ('IQR', 441.42762445145297, 227.80769043235594, 117.15354041551853),\n",
        "       ('Trimmed STD', 465.44974584037317, 187.51507799250015, 92.86257389810629)], \n",
        "      dtype=[('Statistic', 'S11'), ('ndata=5', '<f8'), ('ndata=25', '<f8'), ('ndata=100', '<f8')])"
       ]
      }
     ],
     "prompt_number": 266
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here the true velocity dispersion = 930 km/s. The accuracy is calculated as before. From the tables, we can draw the following conclusions :-\n",
      "\n",
      "__High-z galaxies__\n",
      "\n",
      "In this case, the __Mean Absolute Deviation__ appears to be best statistic choice, with the least spread and bias!\n",
      "\n",
      "__SDSS Galaxies__\n",
      "\n",
      "In this case, the __Trimmed STD__ would be the best choice, since it has the least bias (more than IQR, but it has a higher spread) and relatively less spread. \n",
      "\n",
      "__Intensive Case__\n",
      "\n",
      "While Median Absolute Deviation and IQR would give the true value with the least bias, their high spreads suggest inefficiency. I would once again go with __Trimmed STD__ since it has a low bias and much less spread compared to the other two."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}